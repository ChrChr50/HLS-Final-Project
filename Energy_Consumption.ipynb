{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('powerconsumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "data['Day'] = data['Datetime'].dt.day\n",
    "data['Month'] = data['Datetime'].dt.month\n",
    "data['Hour'] = data['Datetime'].dt.hour\n",
    "data['Day of Week'] = data['Datetime'].dt.dayofweek + 1\n",
    "\n",
    "data = data.drop(['Datetime'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['PowerConsumption_Zone1','PowerConsumption_Zone2','PowerConsumption_Zone3'], axis=1)\n",
    "y = data['PowerConsumption_Zone1']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "def create_mlp_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "983/983 [==============================] - 3s 2ms/step - loss: 166367840.0000 - val_loss: 24990166.0000\n",
      "Epoch 2/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 22827012.0000 - val_loss: 21258212.0000\n",
      "Epoch 3/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 21035692.0000 - val_loss: 20150214.0000\n",
      "Epoch 4/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 20499652.0000 - val_loss: 19833326.0000\n",
      "Epoch 5/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 20128662.0000 - val_loss: 19503372.0000\n",
      "Epoch 6/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 19920908.0000 - val_loss: 19440782.0000\n",
      "Epoch 7/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 19497790.0000 - val_loss: 19152484.0000\n",
      "Epoch 8/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 19186944.0000 - val_loss: 18572614.0000\n",
      "Epoch 9/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 18679286.0000 - val_loss: 18051496.0000\n",
      "Epoch 10/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 18090836.0000 - val_loss: 17136660.0000\n",
      "Epoch 11/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 17321612.0000 - val_loss: 16465293.0000\n",
      "Epoch 12/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 16367326.0000 - val_loss: 17182750.0000\n",
      "Epoch 13/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 15578574.0000 - val_loss: 14753210.0000\n",
      "Epoch 14/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 14981258.0000 - val_loss: 14524257.0000\n",
      "Epoch 15/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 14473146.0000 - val_loss: 14033166.0000\n",
      "Epoch 16/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 14266129.0000 - val_loss: 14327357.0000\n",
      "Epoch 17/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 14143743.0000 - val_loss: 14262954.0000\n",
      "Epoch 18/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 13836275.0000 - val_loss: 13331647.0000\n",
      "Epoch 19/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 13605586.0000 - val_loss: 13584104.0000\n",
      "Epoch 20/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 13523778.0000 - val_loss: 13322661.0000\n",
      "Epoch 21/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 13359870.0000 - val_loss: 13487656.0000\n",
      "Epoch 22/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 13090270.0000 - val_loss: 13071913.0000\n",
      "Epoch 23/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 13125579.0000 - val_loss: 13085808.0000\n",
      "Epoch 24/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 12888112.0000 - val_loss: 13010661.0000\n",
      "Epoch 25/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 12746705.0000 - val_loss: 12257389.0000\n",
      "Epoch 26/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 12539107.0000 - val_loss: 12576069.0000\n",
      "Epoch 27/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 12421562.0000 - val_loss: 12602244.0000\n",
      "Epoch 28/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 12270536.0000 - val_loss: 11905207.0000\n",
      "Epoch 29/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 12137616.0000 - val_loss: 11653327.0000\n",
      "Epoch 30/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 11963188.0000 - val_loss: 12618215.0000\n",
      "Epoch 31/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 11800439.0000 - val_loss: 11295689.0000\n",
      "Epoch 32/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 11567280.0000 - val_loss: 11196773.0000\n",
      "Epoch 33/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 11345884.0000 - val_loss: 11012443.0000\n",
      "Epoch 34/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 11255543.0000 - val_loss: 10681959.0000\n",
      "Epoch 35/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 11102334.0000 - val_loss: 10473004.0000\n",
      "Epoch 36/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 10895635.0000 - val_loss: 10432594.0000\n",
      "Epoch 37/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 10797915.0000 - val_loss: 10052101.0000\n",
      "Epoch 38/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 10640144.0000 - val_loss: 10381470.0000\n",
      "Epoch 39/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 10524554.0000 - val_loss: 9794381.0000\n",
      "Epoch 40/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 10412511.0000 - val_loss: 9939665.0000\n",
      "Epoch 41/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 10241869.0000 - val_loss: 9725143.0000\n",
      "Epoch 42/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 10231807.0000 - val_loss: 9576646.0000\n",
      "Epoch 43/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 10115887.0000 - val_loss: 10044107.0000\n",
      "Epoch 44/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 10022155.0000 - val_loss: 9728872.0000\n",
      "Epoch 45/500\n",
      "983/983 [==============================] - 2s 3ms/step - loss: 10040263.0000 - val_loss: 10090129.0000\n",
      "Epoch 46/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9945321.0000 - val_loss: 10184972.0000\n",
      "Epoch 47/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 9884575.0000 - val_loss: 9322888.0000\n",
      "Epoch 48/500\n",
      "983/983 [==============================] - 4s 4ms/step - loss: 9878564.0000 - val_loss: 9394120.0000\n",
      "Epoch 49/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 9843070.0000 - val_loss: 9064035.0000\n",
      "Epoch 50/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 9771475.0000 - val_loss: 9383187.0000\n",
      "Epoch 51/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 9710056.0000 - val_loss: 9836788.0000\n",
      "Epoch 52/500\n",
      "983/983 [==============================] - 4s 4ms/step - loss: 9691480.0000 - val_loss: 8990416.0000\n",
      "Epoch 53/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9575561.0000 - val_loss: 10680387.0000\n",
      "Epoch 54/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9654624.0000 - val_loss: 9742961.0000\n",
      "Epoch 55/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9575318.0000 - val_loss: 8958059.0000\n",
      "Epoch 56/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9576045.0000 - val_loss: 8999563.0000\n",
      "Epoch 57/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9544131.0000 - val_loss: 9691009.0000\n",
      "Epoch 58/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9445095.0000 - val_loss: 8925707.0000\n",
      "Epoch 59/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9320598.0000 - val_loss: 8733894.0000\n",
      "Epoch 60/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9245122.0000 - val_loss: 9175367.0000\n",
      "Epoch 61/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9399647.0000 - val_loss: 8558114.0000\n",
      "Epoch 62/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9225864.0000 - val_loss: 9051655.0000\n",
      "Epoch 63/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9120513.0000 - val_loss: 8650022.0000\n",
      "Epoch 64/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 9168695.0000 - val_loss: 8413794.0000\n",
      "Epoch 65/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8988273.0000 - val_loss: 9006475.0000\n",
      "Epoch 66/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9095781.0000 - val_loss: 8409850.0000\n",
      "Epoch 67/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 9001017.0000 - val_loss: 8666078.0000\n",
      "Epoch 68/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 9057140.0000 - val_loss: 8418877.0000\n",
      "Epoch 69/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 8875548.0000 - val_loss: 8205093.5000\n",
      "Epoch 70/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 8911433.0000 - val_loss: 8246553.5000\n",
      "Epoch 71/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8875230.0000 - val_loss: 8300596.5000\n",
      "Epoch 72/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8819653.0000 - val_loss: 8172981.5000\n",
      "Epoch 73/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8739879.0000 - val_loss: 8079374.5000\n",
      "Epoch 74/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8754646.0000 - val_loss: 8291327.0000\n",
      "Epoch 75/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8598798.0000 - val_loss: 8401704.0000\n",
      "Epoch 76/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8647639.0000 - val_loss: 8291319.0000\n",
      "Epoch 77/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8677686.0000 - val_loss: 8157769.0000\n",
      "Epoch 78/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8560989.0000 - val_loss: 8155235.0000\n",
      "Epoch 79/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8573824.0000 - val_loss: 8815516.0000\n",
      "Epoch 80/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8516251.0000 - val_loss: 7887483.0000\n",
      "Epoch 81/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8565005.0000 - val_loss: 8000516.0000\n",
      "Epoch 82/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8374215.0000 - val_loss: 7952141.5000\n",
      "Epoch 83/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8420424.0000 - val_loss: 8027253.5000\n",
      "Epoch 84/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8343792.0000 - val_loss: 8441792.0000\n",
      "Epoch 85/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8334763.0000 - val_loss: 8312006.0000\n",
      "Epoch 86/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8272548.5000 - val_loss: 7877686.0000\n",
      "Epoch 87/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8268460.0000 - val_loss: 7777652.0000\n",
      "Epoch 88/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8199102.5000 - val_loss: 8144880.5000\n",
      "Epoch 89/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8040647.5000 - val_loss: 7732644.0000\n",
      "Epoch 90/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8030338.0000 - val_loss: 7565628.0000\n",
      "Epoch 91/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 8043220.5000 - val_loss: 8179146.5000\n",
      "Epoch 92/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7876255.5000 - val_loss: 7572616.5000\n",
      "Epoch 93/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7879328.5000 - val_loss: 7390551.0000\n",
      "Epoch 94/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7867546.5000 - val_loss: 7485398.5000\n",
      "Epoch 95/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7790546.5000 - val_loss: 7777537.0000\n",
      "Epoch 96/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7715348.0000 - val_loss: 7006682.5000\n",
      "Epoch 97/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7666286.5000 - val_loss: 7063689.5000\n",
      "Epoch 98/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 7667112.5000 - val_loss: 7564193.5000\n",
      "Epoch 99/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7611547.0000 - val_loss: 7502198.0000\n",
      "Epoch 100/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7589633.5000 - val_loss: 7164200.5000\n",
      "Epoch 101/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7541595.0000 - val_loss: 7260611.0000\n",
      "Epoch 102/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7488707.0000 - val_loss: 7638431.0000\n",
      "Epoch 103/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7451273.5000 - val_loss: 7316265.5000\n",
      "Epoch 104/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7341306.5000 - val_loss: 6957755.5000\n",
      "Epoch 105/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7433648.0000 - val_loss: 7156135.0000\n",
      "Epoch 106/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7285877.0000 - val_loss: 7182205.5000\n",
      "Epoch 107/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7289343.0000 - val_loss: 7578184.5000\n",
      "Epoch 108/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7280058.0000 - val_loss: 7212905.0000\n",
      "Epoch 109/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7241021.5000 - val_loss: 6796906.0000\n",
      "Epoch 110/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7178419.0000 - val_loss: 6801391.0000\n",
      "Epoch 111/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7180824.0000 - val_loss: 6949194.0000\n",
      "Epoch 112/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7146696.5000 - val_loss: 7026870.5000\n",
      "Epoch 113/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7119055.0000 - val_loss: 8535000.0000\n",
      "Epoch 114/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7052056.0000 - val_loss: 6764752.5000\n",
      "Epoch 115/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6986968.0000 - val_loss: 6793762.5000\n",
      "Epoch 116/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6973191.5000 - val_loss: 7405036.5000\n",
      "Epoch 117/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7049192.0000 - val_loss: 6799227.0000\n",
      "Epoch 118/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6944245.5000 - val_loss: 6494380.5000\n",
      "Epoch 119/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6876846.5000 - val_loss: 7357961.0000\n",
      "Epoch 120/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 7001375.5000 - val_loss: 7292143.0000\n",
      "Epoch 121/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6766240.5000 - val_loss: 6526289.5000\n",
      "Epoch 122/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6797570.5000 - val_loss: 6912432.0000\n",
      "Epoch 123/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6844783.5000 - val_loss: 6307422.5000\n",
      "Epoch 124/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6763290.0000 - val_loss: 7694305.5000\n",
      "Epoch 125/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6702995.5000 - val_loss: 6205062.0000\n",
      "Epoch 126/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6688706.0000 - val_loss: 6170683.0000\n",
      "Epoch 127/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6706361.0000 - val_loss: 6303707.5000\n",
      "Epoch 128/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6635690.5000 - val_loss: 6232382.0000\n",
      "Epoch 129/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6606697.0000 - val_loss: 6782955.0000\n",
      "Epoch 130/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6563579.0000 - val_loss: 6602729.5000\n",
      "Epoch 131/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6521409.0000 - val_loss: 6251830.5000\n",
      "Epoch 132/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6480860.5000 - val_loss: 6413316.5000\n",
      "Epoch 133/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6463764.5000 - val_loss: 6953879.5000\n",
      "Epoch 134/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6371758.5000 - val_loss: 5959513.0000\n",
      "Epoch 135/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6412012.0000 - val_loss: 6518367.5000\n",
      "Epoch 136/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6437004.5000 - val_loss: 5921288.5000\n",
      "Epoch 137/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6391403.0000 - val_loss: 6164678.0000\n",
      "Epoch 138/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6383607.5000 - val_loss: 6116660.5000\n",
      "Epoch 139/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6296841.5000 - val_loss: 8089009.5000\n",
      "Epoch 140/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6356170.5000 - val_loss: 6291667.0000\n",
      "Epoch 141/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6266468.5000 - val_loss: 5864867.0000\n",
      "Epoch 142/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6370268.5000 - val_loss: 6440112.5000\n",
      "Epoch 143/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6240464.5000 - val_loss: 5992336.5000\n",
      "Epoch 144/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6258907.5000 - val_loss: 6186406.5000\n",
      "Epoch 145/500\n",
      "983/983 [==============================] - 3s 3ms/step - loss: 6234667.5000 - val_loss: 6225610.5000\n",
      "Epoch 146/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6210094.5000 - val_loss: 6076239.5000\n",
      "Epoch 147/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6219625.5000 - val_loss: 6020808.0000\n",
      "Epoch 148/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6200305.0000 - val_loss: 6042884.5000\n",
      "Epoch 149/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6127796.5000 - val_loss: 6080806.0000\n",
      "Epoch 150/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6158815.0000 - val_loss: 5604234.5000\n",
      "Epoch 151/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6114730.5000 - val_loss: 5778300.5000\n",
      "Epoch 152/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6105752.0000 - val_loss: 5892930.5000\n",
      "Epoch 153/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6086173.0000 - val_loss: 5607760.5000\n",
      "Epoch 154/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5997148.0000 - val_loss: 5873680.5000\n",
      "Epoch 155/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 6010556.5000 - val_loss: 5766054.5000\n",
      "Epoch 156/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5982373.0000 - val_loss: 5842279.5000\n",
      "Epoch 157/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5986109.0000 - val_loss: 5592752.5000\n",
      "Epoch 158/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5989747.0000 - val_loss: 5873900.5000\n",
      "Epoch 159/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5890469.0000 - val_loss: 7565076.5000\n",
      "Epoch 160/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5990441.0000 - val_loss: 5466317.0000\n",
      "Epoch 161/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5849979.0000 - val_loss: 5852319.5000\n",
      "Epoch 162/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5906143.0000 - val_loss: 5550765.5000\n",
      "Epoch 163/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5896275.0000 - val_loss: 5631939.0000\n",
      "Epoch 164/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5912894.5000 - val_loss: 5870233.5000\n",
      "Epoch 165/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5874065.0000 - val_loss: 5481776.0000\n",
      "Epoch 166/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5839431.0000 - val_loss: 6398048.0000\n",
      "Epoch 167/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5858107.5000 - val_loss: 5891386.0000\n",
      "Epoch 168/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5806372.5000 - val_loss: 5567820.0000\n",
      "Epoch 169/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5834669.5000 - val_loss: 5561714.5000\n",
      "Epoch 170/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5790263.0000 - val_loss: 6283970.5000\n",
      "Epoch 171/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5775115.0000 - val_loss: 6478317.0000\n",
      "Epoch 172/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5824651.0000 - val_loss: 5996896.5000\n",
      "Epoch 173/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5769000.5000 - val_loss: 5889900.5000\n",
      "Epoch 174/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5793211.5000 - val_loss: 6074267.0000\n",
      "Epoch 175/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5876772.5000 - val_loss: 6116341.0000\n",
      "Epoch 176/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5710520.0000 - val_loss: 5602633.5000\n",
      "Epoch 177/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5743675.5000 - val_loss: 5835482.0000\n",
      "Epoch 178/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5780488.5000 - val_loss: 5766500.0000\n",
      "Epoch 179/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5770046.0000 - val_loss: 5261236.5000\n",
      "Epoch 180/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5727890.0000 - val_loss: 7038922.5000\n",
      "Epoch 181/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5702755.5000 - val_loss: 5525387.0000\n",
      "Epoch 182/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5808793.5000 - val_loss: 5762803.0000\n",
      "Epoch 183/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5693856.0000 - val_loss: 5251276.5000\n",
      "Epoch 184/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5640211.0000 - val_loss: 5439236.5000\n",
      "Epoch 185/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5664916.0000 - val_loss: 5377614.5000\n",
      "Epoch 186/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5644545.0000 - val_loss: 5934595.5000\n",
      "Epoch 187/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5638305.0000 - val_loss: 5367196.5000\n",
      "Epoch 188/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5626766.5000 - val_loss: 5345532.5000\n",
      "Epoch 189/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5669946.5000 - val_loss: 5989740.0000\n",
      "Epoch 190/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5623449.5000 - val_loss: 5729936.5000\n",
      "Epoch 191/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5567214.5000 - val_loss: 5870185.5000\n",
      "Epoch 192/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5661290.0000 - val_loss: 5513438.0000\n",
      "Epoch 193/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5611823.0000 - val_loss: 5458005.5000\n",
      "Epoch 194/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5613870.0000 - val_loss: 5745124.5000\n",
      "Epoch 195/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5599657.0000 - val_loss: 5183760.5000\n",
      "Epoch 196/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5593606.0000 - val_loss: 5178816.5000\n",
      "Epoch 197/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5649618.0000 - val_loss: 5315163.0000\n",
      "Epoch 198/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5579962.0000 - val_loss: 5325738.0000\n",
      "Epoch 199/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5565229.5000 - val_loss: 5699498.5000\n",
      "Epoch 200/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5528900.0000 - val_loss: 5409565.0000\n",
      "Epoch 201/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5544875.5000 - val_loss: 5260960.0000\n",
      "Epoch 202/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5624176.5000 - val_loss: 5101100.5000\n",
      "Epoch 203/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5548506.0000 - val_loss: 5298442.5000\n",
      "Epoch 204/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5457558.5000 - val_loss: 5100876.0000\n",
      "Epoch 205/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5529636.5000 - val_loss: 5193247.0000\n",
      "Epoch 206/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5587684.0000 - val_loss: 5365446.5000\n",
      "Epoch 207/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5528638.0000 - val_loss: 5055414.5000\n",
      "Epoch 208/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5558889.5000 - val_loss: 5535916.5000\n",
      "Epoch 209/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5533751.0000 - val_loss: 5538059.5000\n",
      "Epoch 210/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5419759.5000 - val_loss: 5277971.5000\n",
      "Epoch 211/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5459141.0000 - val_loss: 5110607.0000\n",
      "Epoch 212/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5529501.5000 - val_loss: 5814336.5000\n",
      "Epoch 213/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5469940.5000 - val_loss: 5050778.0000\n",
      "Epoch 214/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5474073.5000 - val_loss: 6979200.5000\n",
      "Epoch 215/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5503163.5000 - val_loss: 5563519.5000\n",
      "Epoch 216/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5431362.0000 - val_loss: 5561443.0000\n",
      "Epoch 217/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5372502.5000 - val_loss: 5120821.5000\n",
      "Epoch 218/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5488396.5000 - val_loss: 5497769.5000\n",
      "Epoch 219/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5390945.0000 - val_loss: 5005387.5000\n",
      "Epoch 220/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5428870.5000 - val_loss: 6688431.0000\n",
      "Epoch 221/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5415064.5000 - val_loss: 5141245.5000\n",
      "Epoch 222/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5455417.5000 - val_loss: 5507544.5000\n",
      "Epoch 223/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5406652.0000 - val_loss: 4987821.0000\n",
      "Epoch 224/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5387454.5000 - val_loss: 5100105.5000\n",
      "Epoch 225/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5410902.5000 - val_loss: 5017724.5000\n",
      "Epoch 226/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5359049.5000 - val_loss: 5359144.5000\n",
      "Epoch 227/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5423406.5000 - val_loss: 5225758.0000\n",
      "Epoch 228/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5358605.5000 - val_loss: 5096468.5000\n",
      "Epoch 229/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5409899.5000 - val_loss: 5141645.0000\n",
      "Epoch 230/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5311136.0000 - val_loss: 5365180.5000\n",
      "Epoch 231/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5403720.5000 - val_loss: 5161468.0000\n",
      "Epoch 232/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5281982.5000 - val_loss: 5592913.0000\n",
      "Epoch 233/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5322922.0000 - val_loss: 5131172.5000\n",
      "Epoch 234/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5335695.0000 - val_loss: 5013968.0000\n",
      "Epoch 235/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5335614.5000 - val_loss: 5257479.5000\n",
      "Epoch 236/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5324156.5000 - val_loss: 5935347.0000\n",
      "Epoch 237/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5319246.5000 - val_loss: 5267364.5000\n",
      "Epoch 238/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5297465.0000 - val_loss: 5150682.0000\n",
      "Epoch 239/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5324425.5000 - val_loss: 5089315.5000\n",
      "Epoch 240/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5282819.5000 - val_loss: 5004596.0000\n",
      "Epoch 241/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5346868.5000 - val_loss: 5172395.0000\n",
      "Epoch 242/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5323056.5000 - val_loss: 5643579.0000\n",
      "Epoch 243/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5343937.5000 - val_loss: 4948720.0000\n",
      "Epoch 244/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5237584.5000 - val_loss: 5111747.5000\n",
      "Epoch 245/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5380166.0000 - val_loss: 5061173.0000\n",
      "Epoch 246/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5221526.5000 - val_loss: 5120765.0000\n",
      "Epoch 247/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5259840.5000 - val_loss: 4965063.0000\n",
      "Epoch 248/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5215368.0000 - val_loss: 4928456.0000\n",
      "Epoch 249/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5214047.5000 - val_loss: 4994794.0000\n",
      "Epoch 250/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5280827.0000 - val_loss: 4921260.0000\n",
      "Epoch 251/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5251453.5000 - val_loss: 5240043.5000\n",
      "Epoch 252/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5231591.0000 - val_loss: 5200828.0000\n",
      "Epoch 253/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5198960.5000 - val_loss: 5426164.0000\n",
      "Epoch 254/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5241453.5000 - val_loss: 5334261.0000\n",
      "Epoch 255/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5229826.5000 - val_loss: 4990117.5000\n",
      "Epoch 256/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5223179.0000 - val_loss: 5152777.5000\n",
      "Epoch 257/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5153722.0000 - val_loss: 4981473.5000\n",
      "Epoch 258/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5239927.5000 - val_loss: 5362778.5000\n",
      "Epoch 259/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5205318.5000 - val_loss: 5804065.0000\n",
      "Epoch 260/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5208505.0000 - val_loss: 5372448.0000\n",
      "Epoch 261/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5179178.5000 - val_loss: 4867091.0000\n",
      "Epoch 262/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5148657.0000 - val_loss: 5021644.5000\n",
      "Epoch 263/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5131548.5000 - val_loss: 5169914.5000\n",
      "Epoch 264/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5185542.5000 - val_loss: 5306481.0000\n",
      "Epoch 265/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5106171.5000 - val_loss: 4969666.5000\n",
      "Epoch 266/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5141528.5000 - val_loss: 5513147.0000\n",
      "Epoch 267/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5165538.5000 - val_loss: 5030128.5000\n",
      "Epoch 268/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5170886.5000 - val_loss: 4976899.0000\n",
      "Epoch 269/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5140331.0000 - val_loss: 5070430.5000\n",
      "Epoch 270/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5096195.5000 - val_loss: 5565158.0000\n",
      "Epoch 271/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5124295.0000 - val_loss: 4902133.5000\n",
      "Epoch 272/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5080160.0000 - val_loss: 4927820.5000\n",
      "Epoch 273/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5177207.0000 - val_loss: 4856144.0000\n",
      "Epoch 274/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5075558.5000 - val_loss: 5017108.5000\n",
      "Epoch 275/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5160302.5000 - val_loss: 5774780.5000\n",
      "Epoch 276/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5058182.0000 - val_loss: 5042120.5000\n",
      "Epoch 277/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5114067.0000 - val_loss: 5026963.5000\n",
      "Epoch 278/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5143976.0000 - val_loss: 5098097.0000\n",
      "Epoch 279/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5152505.5000 - val_loss: 6129608.5000\n",
      "Epoch 280/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5108058.5000 - val_loss: 5038586.0000\n",
      "Epoch 281/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5127939.5000 - val_loss: 4825076.5000\n",
      "Epoch 282/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5093312.5000 - val_loss: 5057475.0000\n",
      "Epoch 283/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5141108.0000 - val_loss: 4854269.5000\n",
      "Epoch 284/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5040784.0000 - val_loss: 5709353.0000\n",
      "Epoch 285/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5071737.0000 - val_loss: 5209635.5000\n",
      "Epoch 286/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5042189.0000 - val_loss: 4945229.0000\n",
      "Epoch 287/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5043771.5000 - val_loss: 4979186.0000\n",
      "Epoch 288/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5070049.0000 - val_loss: 5106340.0000\n",
      "Epoch 289/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5122836.0000 - val_loss: 4711312.0000\n",
      "Epoch 290/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5084799.0000 - val_loss: 4769041.5000\n",
      "Epoch 291/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5095059.0000 - val_loss: 4797218.5000\n",
      "Epoch 292/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5053579.5000 - val_loss: 4994693.5000\n",
      "Epoch 293/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5074745.5000 - val_loss: 4904805.5000\n",
      "Epoch 294/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5072144.5000 - val_loss: 4940317.0000\n",
      "Epoch 295/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 5086976.5000 - val_loss: 4863844.5000\n",
      "Epoch 296/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5034538.0000 - val_loss: 4746752.0000\n",
      "Epoch 297/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5036075.5000 - val_loss: 4718941.5000\n",
      "Epoch 298/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5101093.5000 - val_loss: 6035374.0000\n",
      "Epoch 299/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5047380.5000 - val_loss: 5030071.5000\n",
      "Epoch 300/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4962016.5000 - val_loss: 4782482.5000\n",
      "Epoch 301/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4989271.0000 - val_loss: 5368288.5000\n",
      "Epoch 302/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5064390.5000 - val_loss: 4901345.5000\n",
      "Epoch 303/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4995574.0000 - val_loss: 5236999.5000\n",
      "Epoch 304/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5059565.5000 - val_loss: 4756030.0000\n",
      "Epoch 305/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5003759.0000 - val_loss: 5708520.0000\n",
      "Epoch 306/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4997688.0000 - val_loss: 5045537.0000\n",
      "Epoch 307/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5038629.5000 - val_loss: 4767609.0000\n",
      "Epoch 308/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4997922.5000 - val_loss: 4803078.5000\n",
      "Epoch 309/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5025452.5000 - val_loss: 4900202.0000\n",
      "Epoch 310/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5029342.5000 - val_loss: 4850239.0000\n",
      "Epoch 311/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4981897.0000 - val_loss: 5285226.0000\n",
      "Epoch 312/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5006248.0000 - val_loss: 4857494.5000\n",
      "Epoch 313/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4980638.0000 - val_loss: 4860178.5000\n",
      "Epoch 314/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4994313.0000 - val_loss: 5001640.5000\n",
      "Epoch 315/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4973393.0000 - val_loss: 4909878.5000\n",
      "Epoch 316/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 5058353.0000 - val_loss: 4841006.0000\n",
      "Epoch 317/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 5016528.0000 - val_loss: 5234924.0000\n",
      "Epoch 318/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4931638.0000 - val_loss: 4634470.0000\n",
      "Epoch 319/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4981979.5000 - val_loss: 4894683.5000\n",
      "Epoch 320/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4958161.0000 - val_loss: 4923070.0000\n",
      "Epoch 321/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4978583.5000 - val_loss: 4962878.0000\n",
      "Epoch 322/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4962473.5000 - val_loss: 4626836.5000\n",
      "Epoch 323/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4936204.0000 - val_loss: 6339850.0000\n",
      "Epoch 324/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4906161.5000 - val_loss: 4910645.0000\n",
      "Epoch 325/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4907360.0000 - val_loss: 5586542.5000\n",
      "Epoch 326/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4981911.0000 - val_loss: 5381144.0000\n",
      "Epoch 327/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4957184.0000 - val_loss: 4830577.5000\n",
      "Epoch 328/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4933298.0000 - val_loss: 4856664.5000\n",
      "Epoch 329/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4906868.5000 - val_loss: 4690125.5000\n",
      "Epoch 330/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4946928.5000 - val_loss: 6108829.5000\n",
      "Epoch 331/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4943716.5000 - val_loss: 4803097.5000\n",
      "Epoch 332/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4896102.5000 - val_loss: 4789250.0000\n",
      "Epoch 333/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4970829.5000 - val_loss: 4809572.0000\n",
      "Epoch 334/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4937377.0000 - val_loss: 4949887.5000\n",
      "Epoch 335/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4936253.5000 - val_loss: 4769030.5000\n",
      "Epoch 336/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4869933.0000 - val_loss: 4915108.0000\n",
      "Epoch 337/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4932501.0000 - val_loss: 4918987.5000\n",
      "Epoch 338/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4931278.5000 - val_loss: 4690499.0000\n",
      "Epoch 339/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4878501.5000 - val_loss: 4857720.0000\n",
      "Epoch 340/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4905088.0000 - val_loss: 5143256.5000\n",
      "Epoch 341/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4916476.0000 - val_loss: 4665665.0000\n",
      "Epoch 342/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4872691.0000 - val_loss: 5268272.5000\n",
      "Epoch 343/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4929613.5000 - val_loss: 4994679.5000\n",
      "Epoch 344/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4897339.0000 - val_loss: 5639226.5000\n",
      "Epoch 345/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4879075.5000 - val_loss: 5083432.0000\n",
      "Epoch 346/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4888426.0000 - val_loss: 5439310.0000\n",
      "Epoch 347/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4928218.5000 - val_loss: 4718766.0000\n",
      "Epoch 348/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4871891.5000 - val_loss: 4955894.5000\n",
      "Epoch 349/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4904304.5000 - val_loss: 5841608.5000\n",
      "Epoch 350/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4891382.5000 - val_loss: 5054811.0000\n",
      "Epoch 351/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4844742.5000 - val_loss: 5031818.0000\n",
      "Epoch 352/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4873808.0000 - val_loss: 4942983.5000\n",
      "Epoch 353/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4840703.5000 - val_loss: 4730283.0000\n",
      "Epoch 354/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4901154.5000 - val_loss: 4670780.0000\n",
      "Epoch 355/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4859741.5000 - val_loss: 4593646.0000\n",
      "Epoch 356/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4838907.5000 - val_loss: 4659114.0000\n",
      "Epoch 357/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4840283.5000 - val_loss: 5925433.0000\n",
      "Epoch 358/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4814684.0000 - val_loss: 4457398.5000\n",
      "Epoch 359/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4775304.0000 - val_loss: 5696192.5000\n",
      "Epoch 360/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4830445.0000 - val_loss: 4650156.5000\n",
      "Epoch 361/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4821851.0000 - val_loss: 4797112.0000\n",
      "Epoch 362/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4902602.5000 - val_loss: 4807360.5000\n",
      "Epoch 363/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4852585.0000 - val_loss: 4543959.5000\n",
      "Epoch 364/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4801747.0000 - val_loss: 4679456.0000\n",
      "Epoch 365/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4818137.0000 - val_loss: 5314347.5000\n",
      "Epoch 366/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4797431.5000 - val_loss: 4625908.0000\n",
      "Epoch 367/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4810281.0000 - val_loss: 4978955.0000\n",
      "Epoch 368/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4779913.5000 - val_loss: 4809918.0000\n",
      "Epoch 369/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4802202.0000 - val_loss: 4757690.5000\n",
      "Epoch 370/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4778889.5000 - val_loss: 4539418.5000\n",
      "Epoch 371/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4747315.0000 - val_loss: 4940050.5000\n",
      "Epoch 372/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4754660.5000 - val_loss: 4687232.0000\n",
      "Epoch 373/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4785167.5000 - val_loss: 5476685.0000\n",
      "Epoch 374/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4747612.0000 - val_loss: 4650353.5000\n",
      "Epoch 375/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4707850.5000 - val_loss: 4661386.5000\n",
      "Epoch 376/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4774509.0000 - val_loss: 4847579.5000\n",
      "Epoch 377/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4743103.5000 - val_loss: 4630316.5000\n",
      "Epoch 378/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4758048.5000 - val_loss: 4548678.0000\n",
      "Epoch 379/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4695477.0000 - val_loss: 4790982.5000\n",
      "Epoch 380/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4815756.5000 - val_loss: 4596565.5000\n",
      "Epoch 381/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4662812.0000 - val_loss: 4807432.0000\n",
      "Epoch 382/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4718442.5000 - val_loss: 4589247.5000\n",
      "Epoch 383/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4776458.5000 - val_loss: 4816610.5000\n",
      "Epoch 384/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4728731.0000 - val_loss: 4545832.0000\n",
      "Epoch 385/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4704584.5000 - val_loss: 4783362.0000\n",
      "Epoch 386/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4670319.0000 - val_loss: 5052869.5000\n",
      "Epoch 387/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4692530.5000 - val_loss: 4525371.5000\n",
      "Epoch 388/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4628587.5000 - val_loss: 4522937.0000\n",
      "Epoch 389/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4674910.5000 - val_loss: 4710475.5000\n",
      "Epoch 390/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4637667.5000 - val_loss: 4505737.0000\n",
      "Epoch 391/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4698767.0000 - val_loss: 4406036.5000\n",
      "Epoch 392/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4709373.0000 - val_loss: 4742980.5000\n",
      "Epoch 393/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4672447.5000 - val_loss: 5370435.5000\n",
      "Epoch 394/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4667021.5000 - val_loss: 4873654.5000\n",
      "Epoch 395/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4597916.5000 - val_loss: 4448262.5000\n",
      "Epoch 396/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4633755.5000 - val_loss: 4540550.0000\n",
      "Epoch 397/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4703970.5000 - val_loss: 4837131.5000\n",
      "Epoch 398/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4631884.0000 - val_loss: 4523180.5000\n",
      "Epoch 399/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4648359.0000 - val_loss: 5422363.0000\n",
      "Epoch 400/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4653492.5000 - val_loss: 4370285.5000\n",
      "Epoch 401/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4669337.0000 - val_loss: 4527330.5000\n",
      "Epoch 402/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4640568.0000 - val_loss: 4943120.0000\n",
      "Epoch 403/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4606086.5000 - val_loss: 4640636.5000\n",
      "Epoch 404/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4650326.5000 - val_loss: 4879187.0000\n",
      "Epoch 405/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4624079.5000 - val_loss: 4442655.0000\n",
      "Epoch 406/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4593617.5000 - val_loss: 4278140.5000\n",
      "Epoch 407/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4583448.0000 - val_loss: 4698502.0000\n",
      "Epoch 408/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4601084.0000 - val_loss: 4565947.0000\n",
      "Epoch 409/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4602918.5000 - val_loss: 4600434.5000\n",
      "Epoch 410/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4617364.0000 - val_loss: 4467708.0000\n",
      "Epoch 411/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4664341.5000 - val_loss: 4614952.5000\n",
      "Epoch 412/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4569285.5000 - val_loss: 4444264.5000\n",
      "Epoch 413/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4555990.5000 - val_loss: 5272493.5000\n",
      "Epoch 414/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4570024.0000 - val_loss: 4448746.0000\n",
      "Epoch 415/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4515123.0000 - val_loss: 5159605.5000\n",
      "Epoch 416/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4548697.5000 - val_loss: 5069997.0000\n",
      "Epoch 417/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4543036.5000 - val_loss: 4421121.0000\n",
      "Epoch 418/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4546598.5000 - val_loss: 4386701.0000\n",
      "Epoch 419/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4471988.0000 - val_loss: 4277791.0000\n",
      "Epoch 420/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4520864.0000 - val_loss: 6042617.0000\n",
      "Epoch 421/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4500149.0000 - val_loss: 4638282.0000\n",
      "Epoch 422/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4602905.0000 - val_loss: 4870390.5000\n",
      "Epoch 423/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4459018.0000 - val_loss: 4532377.0000\n",
      "Epoch 424/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4507961.5000 - val_loss: 4705314.5000\n",
      "Epoch 425/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4507108.0000 - val_loss: 4282410.0000\n",
      "Epoch 426/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4483546.0000 - val_loss: 4841642.5000\n",
      "Epoch 427/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4449886.0000 - val_loss: 4227093.0000\n",
      "Epoch 428/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4533222.0000 - val_loss: 4384942.5000\n",
      "Epoch 429/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4493947.0000 - val_loss: 4357093.5000\n",
      "Epoch 430/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4466549.0000 - val_loss: 4318922.0000\n",
      "Epoch 431/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4480320.0000 - val_loss: 4366668.5000\n",
      "Epoch 432/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4502877.5000 - val_loss: 4449818.0000\n",
      "Epoch 433/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4439453.0000 - val_loss: 4750505.5000\n",
      "Epoch 434/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4483910.5000 - val_loss: 4895073.0000\n",
      "Epoch 435/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4514245.5000 - val_loss: 4779691.0000\n",
      "Epoch 436/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4463583.5000 - val_loss: 4338885.0000\n",
      "Epoch 437/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4406974.0000 - val_loss: 5199203.5000\n",
      "Epoch 438/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4473617.0000 - val_loss: 4337323.0000\n",
      "Epoch 439/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4361236.5000 - val_loss: 4562812.5000\n",
      "Epoch 440/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4436762.5000 - val_loss: 4163859.0000\n",
      "Epoch 441/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4382882.0000 - val_loss: 4220203.0000\n",
      "Epoch 442/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4400089.5000 - val_loss: 4456129.0000\n",
      "Epoch 443/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4431247.0000 - val_loss: 4444555.0000\n",
      "Epoch 444/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4466986.5000 - val_loss: 4553644.0000\n",
      "Epoch 445/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4411785.0000 - val_loss: 4227092.5000\n",
      "Epoch 446/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4366899.5000 - val_loss: 4139172.7500\n",
      "Epoch 447/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4365318.5000 - val_loss: 4553111.0000\n",
      "Epoch 448/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4408449.0000 - val_loss: 4478080.5000\n",
      "Epoch 449/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4377918.0000 - val_loss: 4436091.5000\n",
      "Epoch 450/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4326750.0000 - val_loss: 4322624.5000\n",
      "Epoch 451/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4314548.0000 - val_loss: 4483581.5000\n",
      "Epoch 452/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4334053.5000 - val_loss: 4833907.5000\n",
      "Epoch 453/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4290272.5000 - val_loss: 4187777.7500\n",
      "Epoch 454/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4329693.5000 - val_loss: 5200199.0000\n",
      "Epoch 455/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4317532.0000 - val_loss: 4232297.0000\n",
      "Epoch 456/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4323567.5000 - val_loss: 4130606.7500\n",
      "Epoch 457/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4338615.0000 - val_loss: 4179090.5000\n",
      "Epoch 458/500\n",
      "983/983 [==============================] - 1s 1ms/step - loss: 4300217.0000 - val_loss: 4667043.0000\n",
      "Epoch 459/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4323499.0000 - val_loss: 4449122.5000\n",
      "Epoch 460/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4281124.5000 - val_loss: 4376098.5000\n",
      "Epoch 461/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4282388.0000 - val_loss: 4054302.7500\n",
      "Epoch 462/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4321302.0000 - val_loss: 4021158.5000\n",
      "Epoch 463/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4241384.5000 - val_loss: 4350618.5000\n",
      "Epoch 464/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4286272.5000 - val_loss: 4262718.0000\n",
      "Epoch 465/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4239389.0000 - val_loss: 4087633.7500\n",
      "Epoch 466/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4271170.5000 - val_loss: 5094947.5000\n",
      "Epoch 467/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4229855.5000 - val_loss: 4394751.5000\n",
      "Epoch 468/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4265629.0000 - val_loss: 4285828.0000\n",
      "Epoch 469/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4206380.0000 - val_loss: 4617396.5000\n",
      "Epoch 470/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4265758.0000 - val_loss: 4235726.0000\n",
      "Epoch 471/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4192247.2500 - val_loss: 4042158.5000\n",
      "Epoch 472/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4195392.5000 - val_loss: 4204689.0000\n",
      "Epoch 473/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4249668.5000 - val_loss: 4246079.5000\n",
      "Epoch 474/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4234757.0000 - val_loss: 4387464.0000\n",
      "Epoch 475/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4175908.0000 - val_loss: 4337820.0000\n",
      "Epoch 476/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4219506.5000 - val_loss: 4355741.5000\n",
      "Epoch 477/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4199805.0000 - val_loss: 4050146.5000\n",
      "Epoch 478/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4194607.5000 - val_loss: 4048538.7500\n",
      "Epoch 479/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4152233.5000 - val_loss: 4209099.5000\n",
      "Epoch 480/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4186456.2500 - val_loss: 3959950.2500\n",
      "Epoch 481/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4150116.2500 - val_loss: 4178329.5000\n",
      "Epoch 482/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4166956.2500 - val_loss: 4145290.0000\n",
      "Epoch 483/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4161798.5000 - val_loss: 4057177.2500\n",
      "Epoch 484/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4179785.5000 - val_loss: 4455871.5000\n",
      "Epoch 485/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4146457.0000 - val_loss: 4838215.5000\n",
      "Epoch 486/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4100499.2500 - val_loss: 4116149.5000\n",
      "Epoch 487/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4114774.2500 - val_loss: 3963041.2500\n",
      "Epoch 488/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4099418.5000 - val_loss: 3977254.2500\n",
      "Epoch 489/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4103882.7500 - val_loss: 3892250.2500\n",
      "Epoch 490/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4125864.7500 - val_loss: 4548186.0000\n",
      "Epoch 491/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4102940.2500 - val_loss: 4098428.0000\n",
      "Epoch 492/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4118999.7500 - val_loss: 3932172.5000\n",
      "Epoch 493/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4111633.2500 - val_loss: 4048169.5000\n",
      "Epoch 494/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4100765.7500 - val_loss: 4129399.7500\n",
      "Epoch 495/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4078846.7500 - val_loss: 4086011.0000\n",
      "Epoch 496/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4068529.7500 - val_loss: 3932032.2500\n",
      "Epoch 497/500\n",
      "983/983 [==============================] - 1s 2ms/step - loss: 4098068.2500 - val_loss: 4341532.5000\n",
      "Epoch 498/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4038658.7500 - val_loss: 4408125.0000\n",
      "Epoch 499/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4110760.5000 - val_loss: 4046067.0000\n",
      "Epoch 500/500\n",
      "983/983 [==============================] - 2s 2ms/step - loss: 4036657.2500 - val_loss: 4152895.5000\n"
     ]
    }
   ],
   "source": [
    "model = create_mlp_model(X_train.shape[1])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983/983 [==============================] - 1s 798us/step\n",
      "328/328 [==============================] - 0s 786us/step\n",
      "328/328 [==============================] - 0s 796us/step\n",
      "Training MSE: 4008746.436809497\n",
      "Validation MSE: 4152892.610869986\n",
      "Test MSE: 4003412.6969335307\n",
      "Training R-squared: 0.9212679374785825\n",
      "Validation R-squared: 0.9184801172423318\n",
      "Test R-squared: 0.9207156877841893\n",
      "15506    32985.14532\n",
      "51943    34737.64259\n",
      "212      27894.68354\n",
      "11210    42476.93617\n",
      "16307    21341.14101\n",
      "Name: PowerConsumption_Zone1, dtype: float64\n",
      "[[32959.84 ]\n",
      " [37248.496]\n",
      " [30683.56 ]\n",
      " [43849.438]\n",
      " [23095.107]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Training MSE:\", mean_squared_error(Y_train, Y_train_pred))\n",
    "    print(\"Validation MSE:\", mean_squared_error(Y_val, Y_val_pred))\n",
    "    print(\"Test MSE:\", mean_squared_error(Y_test, Y_test_pred))\n",
    "\n",
    "    print(\"Training R-squared:\", r2_score(Y_train, Y_train_pred))\n",
    "    print(\"Validation R-squared:\", r2_score(Y_val, Y_val_pred))\n",
    "    print(\"Test R-squared:\", r2_score(Y_test, Y_test_pred))\n",
    "\n",
    "    print(Y_test[0:5])\n",
    "    print(Y_test_pred[0:5])\n",
    "\n",
    "evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_directory\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_directory\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('saved_model_directory')\n",
    "\n",
    "# Extract weights and biases\n",
    "weights = model.get_weights()\n",
    "\n",
    "# Save to a C++ readable file\n",
    "with open('mlp_weights.cpp', 'w') as f:\n",
    "    for i, w in enumerate(weights):\n",
    "        if len(w.shape) == 2:  # Dense layer weights (matrix)\n",
    "            f.write(f\"const float W{i}[][] = {{\\n\")\n",
    "            for row in w:\n",
    "                f.write(\"    {\" + \", \".join(map(str, row)) + \"},\\n\")\n",
    "            f.write(\"};\\n\\n\")\n",
    "        elif len(w.shape) == 1:  # Dense layer biases (vector)\n",
    "            f.write(f\"const float B{i}[] = {{\" + \", \".join(map(str, w)) + \"};\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to test_data.cpp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Limit to 150 rows\n",
    "X_test = X_test.iloc[:150]\n",
    "y_test = y_test.iloc[:150]\n",
    "\n",
    "# Define the C++ file name\n",
    "filename = \"test_data.cpp\"\n",
    "\n",
    "# Generate C++ array declarations\n",
    "x_array_name = \"x_test\"\n",
    "y_array_name = \"y_test\"\n",
    "\n",
    "if X_test.empty:\n",
    "    raise ValueError(\"X_test is empty\")\n",
    "if y_test.empty:\n",
    "    raise ValueError(\"y_test is empty\")\n",
    "\n",
    "num_rows, num_cols = X_test.shape\n",
    "\n",
    "# Write to the C++ file\n",
    "with open(filename, mode='w') as file:\n",
    "    # Write a comment and include guard\n",
    "    file.write(\"// Test datasets exported from Python\\n\")\n",
    "    \n",
    "    # Write x_test array\n",
    "    file.write(f\"const int x_num_rows = {num_rows};\\n\")\n",
    "    file.write(f\"const int x_num_cols = {num_cols};\\n\")\n",
    "    file.write(f\"const float {x_array_name}[{num_rows}][{num_cols}] = {{\\n\")\n",
    "    for row in X_test.values:  # Convert to NumPy array for iteration\n",
    "        row_str = \", \".join(f\"{value:.8f}\" for value in row)  # Format numbers for precision\n",
    "        file.write(f\"    {{ {row_str} }},\\n\")\n",
    "    file.write(\"};\\n\\n\")\n",
    "    \n",
    "    # Write y_test array\n",
    "    file.write(f\"const int y_num_rows = {len(y_test)};\\n\")\n",
    "    file.write(f\"const float {y_array_name}[{len(y_test)}] = {{\\n\")\n",
    "    y_str = \", \".join(f\"{value}\" for value in y_test)\n",
    "    file.write(f\"    {y_str}\\n\")\n",
    "    file.write(\"};\\n\")\n",
    "\n",
    "print(f\"Data successfully exported to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
